{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "XXp5mAgXfRv9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.backend.set_floatx(\"float64\")  # we want to carry out GP calculations in 64 bit\n",
        "tf.get_logger().setLevel(\"INFO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config:\n",
        "    num_inducing=50\n",
        "    inner_layer_qsqrt_factor=1e-5\n",
        "    likelihood_noise_variance=1e-2\n",
        "    whiten=True\n",
        "\n",
        "    num_layers=20\n",
        "\n",
        "\n",
        "    # Training\n",
        "    batch_size=24\n",
        "    learning_rate=0.01\n",
        "    epochs = 30\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "1OZWWCI5MYVq"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "OZ4eQopyCy6F"
      },
      "outputs": [],
      "source": [
        "def return_data(fold,month,with_scaling, station_id = None):\n",
        "  train_input = pd.read_csv('data/beijing-18/time_feature/'+'/fold'+str(fold)+'/train_data_'+month+'_nsgp.csv.gz')\n",
        "  test_input = pd.read_csv('data/beijing-18/time_feature'+'/fold'+str(fold)+'/test_data_'+month+'_nsgp.csv.gz')\n",
        "  if station_id != None:\n",
        "    test_input = test_input[test_input['station_id'] == station_id]\n",
        "  #     test_input = test_input[test_input['station_id' == ]]\n",
        "  test_output = np.array(test_input['PM25_Concentration'])\n",
        "  train_output = np.array(train_input['PM25_Concentration'])\n",
        "  train_input= train_input.drop(['station_id','PM25_Concentration','time','filled'],axis=1)\n",
        "  try:\n",
        "    test_input= test_input.drop(['PM25_Concentration','station_id','time','filled'],axis=1)\n",
        "  except:\n",
        "    test_input= test_input.drop(['station_id','time','filled'],axis=1)\n",
        "  #     test_output= test_output.drop(['time'],axis=1)\n",
        "  if with_scaling:\n",
        "    scaler = StandardScaler().fit(train_input)\n",
        "    train_input = pd.DataFrame(scaler.transform(train_input),columns=list(train_input.columns))\n",
        "    test_input = pd.DataFrame(scaler.transform(test_input),columns=list(test_input.columns))\n",
        "  return train_input,train_output,test_input,test_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "pJrTrqNYfxH4"
      },
      "outputs": [],
      "source": [
        "# np.random.seed(42)\n",
        "# X=np.random.rand(100,2)\n",
        "# # noise=np.random.normal(0,1,100)\n",
        "# Y=-8*X[:,0] - 6*X[:,1] + 3\n",
        "# X=X\n",
        "# # print(X)\n",
        "# # X=X.reshape(-1,1)\n",
        "# Y=Y.reshape(-1,1)\n",
        "# print(X.shape)\n",
        "# print\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "QEGzfSUBg1Pm"
      },
      "outputs": [],
      "source": [
        "# plt.plot(train_input.iloc[:,1], train_output, \"kx\")\n",
        "# plt.xlabel(\"X\")\n",
        "# plt.ylabel(\"Y\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02-TBrbliyWF",
        "outputId": "0eacd47f-2436-482a-856e-6dbb35fa53b6"
      },
      "outputs": [],
      "source": [
        "# !pip install gpflux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [],
      "source": [
        "# os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]= '0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLViLwxWg2X3",
        "outputId": "a608a5e6-5aad-4146-ae40-8c5c74cac732"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(14880, 8) (14880, 1)\n",
            "Fold:  0\n",
            "Data received\n",
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Cannot pickle Tensor -- its value is not known statically: Tensor(\"gp_0/Identity_2:0\", shape=(), dtype=float64).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-26 16:39:31.484568: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
            "2022-03-26 16:39:31.484627: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
            "2022-03-26 16:39:31.485788: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
            "2022-03-26 16:39:31.485916: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "  2/620 [..............................] - ETA: 7:06 - loss: 608246.7825 - gp_0_prior_kl: 0.2032 - gp_1_prior_kl: 0.2032 - gp_2_prior_kl: 0.2032 - gp_3_prior_kl: 0.2032 - gp_4_prior_kl: 0.2032 - gp_5_prior_kl: 0.2032 - gp_6_prior_kl: 0.2032 - gp_7_prior_kl: 0.2032 - gp_8_prior_kl: 0.2032 - gp_9_prior_kl: 0.2032 - gp_10_prior_kl: 0.2032 - gp_11_prior_kl: 0.2032 - gp_12_prior_kl: 0.2032 - gp_13_prior_kl: 0.2032 - gp_14_prior_kl: 0.2032 - gp_15_prior_kl: 0.2032 - gp_16_prior_kl: 0.2032 - gp_17_prior_kl: 0.2032 - gp_18_prior_kl: 0.2032 - gp_19_prior_kl: 2.3101e-06   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-26 16:39:50.921906: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
            "2022-03-26 16:39:50.921984: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
            "2022-03-26 16:39:52.029924: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
            "2022-03-26 16:39:52.036036: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
            "2022-03-26 16:39:52.153775: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
            "2022-03-26 16:39:52.174264: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
            "2022-03-26 16:39:52.214666: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/train/plugins/profile/2022_03_26_16_39_52\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  6/620 [..............................] - ETA: 4:19 - loss: 599128.4215 - gp_0_prior_kl: 0.1263 - gp_1_prior_kl: 0.1263 - gp_2_prior_kl: 0.1263 - gp_3_prior_kl: 0.1263 - gp_4_prior_kl: 0.1263 - gp_5_prior_kl: 0.1263 - gp_6_prior_kl: 0.1263 - gp_7_prior_kl: 0.1263 - gp_8_prior_kl: 0.1263 - gp_9_prior_kl: 0.1263 - gp_10_prior_kl: 0.1263 - gp_11_prior_kl: 0.1263 - gp_12_prior_kl: 0.1263 - gp_13_prior_kl: 0.1263 - gp_14_prior_kl: 0.1263 - gp_15_prior_kl: 0.1263 - gp_16_prior_kl: 0.1263 - gp_17_prior_kl: 0.1263 - gp_18_prior_kl: 0.1263 - gp_19_prior_kl: 2.1538e-05 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-26 16:39:52.233937: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to logs/train/plugins/profile/2022_03_26_16_39_52/ramanujan.trace.json.gz\n",
            "2022-03-26 16:39:52.269105: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/train/plugins/profile/2022_03_26_16_39_52\n",
            "2022-03-26 16:39:52.269363: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to logs/train/plugins/profile/2022_03_26_16_39_52/ramanujan.memory_profile.json.gz\n",
            "2022-03-26 16:39:52.272288: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/train/plugins/profile/2022_03_26_16_39_52Dumped tool data for xplane.pb to logs/train/plugins/profile/2022_03_26_16_39_52/ramanujan.xplane.pb\n",
            "Dumped tool data for overview_page.pb to logs/train/plugins/profile/2022_03_26_16_39_52/ramanujan.overview_page.pb\n",
            "Dumped tool data for input_pipeline.pb to logs/train/plugins/profile/2022_03_26_16_39_52/ramanujan.input_pipeline.pb\n",
            "Dumped tool data for tensorflow_stats.pb to logs/train/plugins/profile/2022_03_26_16_39_52/ramanujan.tensorflow_stats.pb\n",
            "Dumped tool data for kernel_stats.pb to logs/train/plugins/profile/2022_03_26_16_39_52/ramanujan.kernel_stats.pb\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "620/620 [==============================] - 35s 27ms/step - loss: 143318.9745 - gp_0_prior_kl: 0.1521 - gp_1_prior_kl: 0.1571 - gp_2_prior_kl: 0.1515 - gp_3_prior_kl: 0.1550 - gp_4_prior_kl: 0.1529 - gp_5_prior_kl: 0.1540 - gp_6_prior_kl: 0.1542 - gp_7_prior_kl: 0.1539 - gp_8_prior_kl: 0.1584 - gp_9_prior_kl: 0.1540 - gp_10_prior_kl: 0.1537 - gp_11_prior_kl: 0.1527 - gp_12_prior_kl: 0.1537 - gp_13_prior_kl: 0.1539 - gp_14_prior_kl: 0.1520 - gp_15_prior_kl: 0.1527 - gp_16_prior_kl: 0.1533 - gp_17_prior_kl: 0.1527 - gp_18_prior_kl: 0.1556 - gp_19_prior_kl: 0.0179\n",
            "Epoch 2/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 16097.1980 - gp_0_prior_kl: 0.2124 - gp_1_prior_kl: 0.2143 - gp_2_prior_kl: 0.2109 - gp_3_prior_kl: 0.2191 - gp_4_prior_kl: 0.2117 - gp_5_prior_kl: 0.2150 - gp_6_prior_kl: 0.2177 - gp_7_prior_kl: 0.2143 - gp_8_prior_kl: 0.2207 - gp_9_prior_kl: 0.2124 - gp_10_prior_kl: 0.2111 - gp_11_prior_kl: 0.2106 - gp_12_prior_kl: 0.2103 - gp_13_prior_kl: 0.2169 - gp_14_prior_kl: 0.2130 - gp_15_prior_kl: 0.2074 - gp_16_prior_kl: 0.2105 - gp_17_prior_kl: 0.2120 - gp_18_prior_kl: 0.2141 - gp_19_prior_kl: 0.0530\n",
            "Epoch 3/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 7406.6797 - gp_0_prior_kl: 0.2300 - gp_1_prior_kl: 0.2232 - gp_2_prior_kl: 0.2297 - gp_3_prior_kl: 0.2326 - gp_4_prior_kl: 0.2234 - gp_5_prior_kl: 0.2279 - gp_6_prior_kl: 0.2268 - gp_7_prior_kl: 0.2307 - gp_8_prior_kl: 0.2456 - gp_9_prior_kl: 0.2275 - gp_10_prior_kl: 0.2326 - gp_11_prior_kl: 0.2273 - gp_12_prior_kl: 0.2284 - gp_13_prior_kl: 0.2372 - gp_14_prior_kl: 0.2362 - gp_15_prior_kl: 0.2214 - gp_16_prior_kl: 0.2299 - gp_17_prior_kl: 0.2324 - gp_18_prior_kl: 0.2322 - gp_19_prior_kl: 0.0745\n",
            "Epoch 4/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 4211.4116 - gp_0_prior_kl: 0.2334 - gp_1_prior_kl: 0.2202 - gp_2_prior_kl: 0.2375 - gp_3_prior_kl: 0.2364 - gp_4_prior_kl: 0.2281 - gp_5_prior_kl: 0.2330 - gp_6_prior_kl: 0.2310 - gp_7_prior_kl: 0.2428 - gp_8_prior_kl: 0.2498 - gp_9_prior_kl: 0.2379 - gp_10_prior_kl: 0.2576 - gp_11_prior_kl: 0.2347 - gp_12_prior_kl: 0.2433 - gp_13_prior_kl: 0.2632 - gp_14_prior_kl: 0.2499 - gp_15_prior_kl: 0.2367 - gp_16_prior_kl: 0.2513 - gp_17_prior_kl: 0.2451 - gp_18_prior_kl: 0.2488 - gp_19_prior_kl: 0.0923\n",
            "Epoch 5/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 2743.6411 - gp_0_prior_kl: 0.2362 - gp_1_prior_kl: 0.2207 - gp_2_prior_kl: 0.2386 - gp_3_prior_kl: 0.2370 - gp_4_prior_kl: 0.2331 - gp_5_prior_kl: 0.2317 - gp_6_prior_kl: 0.2341 - gp_7_prior_kl: 0.2445 - gp_8_prior_kl: 0.2457 - gp_9_prior_kl: 0.2361 - gp_10_prior_kl: 0.2727 - gp_11_prior_kl: 0.2444 - gp_12_prior_kl: 0.2522 - gp_13_prior_kl: 0.2818 - gp_14_prior_kl: 0.2667 - gp_15_prior_kl: 0.2560 - gp_16_prior_kl: 0.2635 - gp_17_prior_kl: 0.2559 - gp_18_prior_kl: 0.2581 - gp_19_prior_kl: 0.1072\n",
            "Epoch 6/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 1927.8163 - gp_0_prior_kl: 0.2354 - gp_1_prior_kl: 0.2224 - gp_2_prior_kl: 0.2338 - gp_3_prior_kl: 0.2404 - gp_4_prior_kl: 0.2346 - gp_5_prior_kl: 0.2300 - gp_6_prior_kl: 0.2349 - gp_7_prior_kl: 0.2437 - gp_8_prior_kl: 0.2445 - gp_9_prior_kl: 0.2352 - gp_10_prior_kl: 0.2777 - gp_11_prior_kl: 0.2545 - gp_12_prior_kl: 0.2565 - gp_13_prior_kl: 0.2904 - gp_14_prior_kl: 0.2760 - gp_15_prior_kl: 0.2668 - gp_16_prior_kl: 0.2676 - gp_17_prior_kl: 0.2615 - gp_18_prior_kl: 0.2657 - gp_19_prior_kl: 0.1195\n",
            "Epoch 7/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 1436.4913 - gp_0_prior_kl: 0.2362 - gp_1_prior_kl: 0.2222 - gp_2_prior_kl: 0.2339 - gp_3_prior_kl: 0.2426 - gp_4_prior_kl: 0.2323 - gp_5_prior_kl: 0.2270 - gp_6_prior_kl: 0.2353 - gp_7_prior_kl: 0.2501 - gp_8_prior_kl: 0.2435 - gp_9_prior_kl: 0.2303 - gp_10_prior_kl: 0.2816 - gp_11_prior_kl: 0.2576 - gp_12_prior_kl: 0.2652 - gp_13_prior_kl: 0.2951 - gp_14_prior_kl: 0.2825 - gp_15_prior_kl: 0.2704 - gp_16_prior_kl: 0.2731 - gp_17_prior_kl: 0.2704 - gp_18_prior_kl: 0.2723 - gp_19_prior_kl: 0.1299\n",
            "Epoch 8/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 1102.3426 - gp_0_prior_kl: 0.2374 - gp_1_prior_kl: 0.2233 - gp_2_prior_kl: 0.2319 - gp_3_prior_kl: 0.2419 - gp_4_prior_kl: 0.2324 - gp_5_prior_kl: 0.2264 - gp_6_prior_kl: 0.2369 - gp_7_prior_kl: 0.2531 - gp_8_prior_kl: 0.2396 - gp_9_prior_kl: 0.2281 - gp_10_prior_kl: 0.2838 - gp_11_prior_kl: 0.2608 - gp_12_prior_kl: 0.2747 - gp_13_prior_kl: 0.2949 - gp_14_prior_kl: 0.2918 - gp_15_prior_kl: 0.2770 - gp_16_prior_kl: 0.2793 - gp_17_prior_kl: 0.2782 - gp_18_prior_kl: 0.2782 - gp_19_prior_kl: 0.1386\n",
            "Epoch 9/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 864.7399 - gp_0_prior_kl: 0.2368 - gp_1_prior_kl: 0.2277 - gp_2_prior_kl: 0.2314 - gp_3_prior_kl: 0.2412 - gp_4_prior_kl: 0.2333 - gp_5_prior_kl: 0.2225 - gp_6_prior_kl: 0.2350 - gp_7_prior_kl: 0.2512 - gp_8_prior_kl: 0.2389 - gp_9_prior_kl: 0.2267 - gp_10_prior_kl: 0.2893 - gp_11_prior_kl: 0.2619 - gp_12_prior_kl: 0.2781 - gp_13_prior_kl: 0.2985 - gp_14_prior_kl: 0.2897 - gp_15_prior_kl: 0.2797 - gp_16_prior_kl: 0.2834 - gp_17_prior_kl: 0.2855 - gp_18_prior_kl: 0.2869 - gp_19_prior_kl: 0.1466\n",
            "Epoch 10/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 691.6890 - gp_0_prior_kl: 0.2353 - gp_1_prior_kl: 0.2231 - gp_2_prior_kl: 0.2304 - gp_3_prior_kl: 0.2436 - gp_4_prior_kl: 0.2342 - gp_5_prior_kl: 0.2216 - gp_6_prior_kl: 0.2332 - gp_7_prior_kl: 0.2492 - gp_8_prior_kl: 0.2391 - gp_9_prior_kl: 0.2250 - gp_10_prior_kl: 0.2964 - gp_11_prior_kl: 0.2616 - gp_12_prior_kl: 0.2869 - gp_13_prior_kl: 0.2998 - gp_14_prior_kl: 0.2922 - gp_15_prior_kl: 0.2803 - gp_16_prior_kl: 0.2869 - gp_17_prior_kl: 0.2918 - gp_18_prior_kl: 0.2939 - gp_19_prior_kl: 0.1542\n",
            "Epoch 11/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 549.5713 - gp_0_prior_kl: 0.2343 - gp_1_prior_kl: 0.2213 - gp_2_prior_kl: 0.2300 - gp_3_prior_kl: 0.2468 - gp_4_prior_kl: 0.2347 - gp_5_prior_kl: 0.2209 - gp_6_prior_kl: 0.2311 - gp_7_prior_kl: 0.2468 - gp_8_prior_kl: 0.2391 - gp_9_prior_kl: 0.2248 - gp_10_prior_kl: 0.3039 - gp_11_prior_kl: 0.2642 - gp_12_prior_kl: 0.2915 - gp_13_prior_kl: 0.3011 - gp_14_prior_kl: 0.2949 - gp_15_prior_kl: 0.2825 - gp_16_prior_kl: 0.2880 - gp_17_prior_kl: 0.2950 - gp_18_prior_kl: 0.2978 - gp_19_prior_kl: 0.1612\n",
            "Epoch 12/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 451.8079 - gp_0_prior_kl: 0.2316 - gp_1_prior_kl: 0.2205 - gp_2_prior_kl: 0.2282 - gp_3_prior_kl: 0.2491 - gp_4_prior_kl: 0.2351 - gp_5_prior_kl: 0.2202 - gp_6_prior_kl: 0.2334 - gp_7_prior_kl: 0.2437 - gp_8_prior_kl: 0.2367 - gp_9_prior_kl: 0.2228 - gp_10_prior_kl: 0.3092 - gp_11_prior_kl: 0.2642 - gp_12_prior_kl: 0.2991 - gp_13_prior_kl: 0.3014 - gp_14_prior_kl: 0.2970 - gp_15_prior_kl: 0.2814 - gp_16_prior_kl: 0.2868 - gp_17_prior_kl: 0.2983 - gp_18_prior_kl: 0.3031 - gp_19_prior_kl: 0.1682\n",
            "Epoch 13/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 367.0920 - gp_0_prior_kl: 0.2298 - gp_1_prior_kl: 0.2197 - gp_2_prior_kl: 0.2272 - gp_3_prior_kl: 0.2506 - gp_4_prior_kl: 0.2343 - gp_5_prior_kl: 0.2219 - gp_6_prior_kl: 0.2329 - gp_7_prior_kl: 0.2424 - gp_8_prior_kl: 0.2362 - gp_9_prior_kl: 0.2193 - gp_10_prior_kl: 0.3167 - gp_11_prior_kl: 0.2629 - gp_12_prior_kl: 0.3053 - gp_13_prior_kl: 0.3027 - gp_14_prior_kl: 0.3002 - gp_15_prior_kl: 0.2858 - gp_16_prior_kl: 0.2879 - gp_17_prior_kl: 0.3010 - gp_18_prior_kl: 0.3082 - gp_19_prior_kl: 0.1742\n",
            "Epoch 14/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 316.9109 - gp_0_prior_kl: 0.2265 - gp_1_prior_kl: 0.2179 - gp_2_prior_kl: 0.2288 - gp_3_prior_kl: 0.2526 - gp_4_prior_kl: 0.2402 - gp_5_prior_kl: 0.2226 - gp_6_prior_kl: 0.2336 - gp_7_prior_kl: 0.2399 - gp_8_prior_kl: 0.2323 - gp_9_prior_kl: 0.2180 - gp_10_prior_kl: 0.3207 - gp_11_prior_kl: 0.2638 - gp_12_prior_kl: 0.3165 - gp_13_prior_kl: 0.3041 - gp_14_prior_kl: 0.2992 - gp_15_prior_kl: 0.2890 - gp_16_prior_kl: 0.2854 - gp_17_prior_kl: 0.3051 - gp_18_prior_kl: 0.3126 - gp_19_prior_kl: 0.1795\n",
            "Epoch 15/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 268.7686 - gp_0_prior_kl: 0.2270 - gp_1_prior_kl: 0.2162 - gp_2_prior_kl: 0.2276 - gp_3_prior_kl: 0.2553 - gp_4_prior_kl: 0.2393 - gp_5_prior_kl: 0.2219 - gp_6_prior_kl: 0.2319 - gp_7_prior_kl: 0.2394 - gp_8_prior_kl: 0.2281 - gp_9_prior_kl: 0.2146 - gp_10_prior_kl: 0.3254 - gp_11_prior_kl: 0.2622 - gp_12_prior_kl: 0.3236 - gp_13_prior_kl: 0.3050 - gp_14_prior_kl: 0.3000 - gp_15_prior_kl: 0.2923 - gp_16_prior_kl: 0.2856 - gp_17_prior_kl: 0.3055 - gp_18_prior_kl: 0.3172 - gp_19_prior_kl: 0.1850\n",
            "Epoch 16/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 227.5659 - gp_0_prior_kl: 0.2256 - gp_1_prior_kl: 0.2116 - gp_2_prior_kl: 0.2262 - gp_3_prior_kl: 0.2572 - gp_4_prior_kl: 0.2346 - gp_5_prior_kl: 0.2203 - gp_6_prior_kl: 0.2290 - gp_7_prior_kl: 0.2387 - gp_8_prior_kl: 0.2244 - gp_9_prior_kl: 0.2095 - gp_10_prior_kl: 0.3268 - gp_11_prior_kl: 0.2617 - gp_12_prior_kl: 0.3301 - gp_13_prior_kl: 0.3042 - gp_14_prior_kl: 0.3001 - gp_15_prior_kl: 0.2911 - gp_16_prior_kl: 0.2830 - gp_17_prior_kl: 0.3063 - gp_18_prior_kl: 0.3205 - gp_19_prior_kl: 0.1904\n",
            "Epoch 17/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 196.5705 - gp_0_prior_kl: 0.2213 - gp_1_prior_kl: 0.2107 - gp_2_prior_kl: 0.2226 - gp_3_prior_kl: 0.2628 - gp_4_prior_kl: 0.2329 - gp_5_prior_kl: 0.2201 - gp_6_prior_kl: 0.2263 - gp_7_prior_kl: 0.2362 - gp_8_prior_kl: 0.2176 - gp_9_prior_kl: 0.2065 - gp_10_prior_kl: 0.3275 - gp_11_prior_kl: 0.2635 - gp_12_prior_kl: 0.3365 - gp_13_prior_kl: 0.3035 - gp_14_prior_kl: 0.3024 - gp_15_prior_kl: 0.2919 - gp_16_prior_kl: 0.2838 - gp_17_prior_kl: 0.3080 - gp_18_prior_kl: 0.3252 - gp_19_prior_kl: 0.1964\n",
            "Epoch 18/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 172.2045 - gp_0_prior_kl: 0.2173 - gp_1_prior_kl: 0.2112 - gp_2_prior_kl: 0.2231 - gp_3_prior_kl: 0.2652 - gp_4_prior_kl: 0.2338 - gp_5_prior_kl: 0.2179 - gp_6_prior_kl: 0.2260 - gp_7_prior_kl: 0.2335 - gp_8_prior_kl: 0.2105 - gp_9_prior_kl: 0.2004 - gp_10_prior_kl: 0.3287 - gp_11_prior_kl: 0.2652 - gp_12_prior_kl: 0.3405 - gp_13_prior_kl: 0.3029 - gp_14_prior_kl: 0.3065 - gp_15_prior_kl: 0.2949 - gp_16_prior_kl: 0.2833 - gp_17_prior_kl: 0.3081 - gp_18_prior_kl: 0.3315 - gp_19_prior_kl: 0.2020\n",
            "Epoch 19/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 151.3293 - gp_0_prior_kl: 0.2153 - gp_1_prior_kl: 0.2105 - gp_2_prior_kl: 0.2193 - gp_3_prior_kl: 0.2640 - gp_4_prior_kl: 0.2307 - gp_5_prior_kl: 0.2081 - gp_6_prior_kl: 0.2257 - gp_7_prior_kl: 0.2292 - gp_8_prior_kl: 0.2043 - gp_9_prior_kl: 0.1955 - gp_10_prior_kl: 0.3315 - gp_11_prior_kl: 0.2627 - gp_12_prior_kl: 0.3431 - gp_13_prior_kl: 0.3010 - gp_14_prior_kl: 0.3123 - gp_15_prior_kl: 0.2970 - gp_16_prior_kl: 0.2810 - gp_17_prior_kl: 0.3068 - gp_18_prior_kl: 0.3367 - gp_19_prior_kl: 0.2071\n",
            "Epoch 20/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 135.9780 - gp_0_prior_kl: 0.2139 - gp_1_prior_kl: 0.2083 - gp_2_prior_kl: 0.2151 - gp_3_prior_kl: 0.2677 - gp_4_prior_kl: 0.2316 - gp_5_prior_kl: 0.2005 - gp_6_prior_kl: 0.2204 - gp_7_prior_kl: 0.2239 - gp_8_prior_kl: 0.2013 - gp_9_prior_kl: 0.1896 - gp_10_prior_kl: 0.3328 - gp_11_prior_kl: 0.2628 - gp_12_prior_kl: 0.3469 - gp_13_prior_kl: 0.3024 - gp_14_prior_kl: 0.3135 - gp_15_prior_kl: 0.2992 - gp_16_prior_kl: 0.2785 - gp_17_prior_kl: 0.3025 - gp_18_prior_kl: 0.3331 - gp_19_prior_kl: 0.2114\n",
            "Epoch 21/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 115.1916 - gp_0_prior_kl: 0.2109 - gp_1_prior_kl: 0.2035 - gp_2_prior_kl: 0.2070 - gp_3_prior_kl: 0.2697 - gp_4_prior_kl: 0.2263 - gp_5_prior_kl: 0.1937 - gp_6_prior_kl: 0.2165 - gp_7_prior_kl: 0.2169 - gp_8_prior_kl: 0.1944 - gp_9_prior_kl: 0.1810 - gp_10_prior_kl: 0.3369 - gp_11_prior_kl: 0.2612 - gp_12_prior_kl: 0.3497 - gp_13_prior_kl: 0.3012 - gp_14_prior_kl: 0.3167 - gp_15_prior_kl: 0.3018 - gp_16_prior_kl: 0.2733 - gp_17_prior_kl: 0.3003 - gp_18_prior_kl: 0.3338 - gp_19_prior_kl: 0.2169\n",
            "Epoch 22/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 105.9366 - gp_0_prior_kl: 0.2084 - gp_1_prior_kl: 0.1962 - gp_2_prior_kl: 0.2000 - gp_3_prior_kl: 0.2709 - gp_4_prior_kl: 0.2227 - gp_5_prior_kl: 0.1860 - gp_6_prior_kl: 0.2140 - gp_7_prior_kl: 0.2083 - gp_8_prior_kl: 0.1886 - gp_9_prior_kl: 0.1699 - gp_10_prior_kl: 0.3388 - gp_11_prior_kl: 0.2601 - gp_12_prior_kl: 0.3529 - gp_13_prior_kl: 0.2983 - gp_14_prior_kl: 0.3181 - gp_15_prior_kl: 0.3046 - gp_16_prior_kl: 0.2665 - gp_17_prior_kl: 0.3034 - gp_18_prior_kl: 0.3335 - gp_19_prior_kl: 0.2206\n",
            "Epoch 23/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 91.3632 - gp_0_prior_kl: 0.2053 - gp_1_prior_kl: 0.1875 - gp_2_prior_kl: 0.1937 - gp_3_prior_kl: 0.2730 - gp_4_prior_kl: 0.2179 - gp_5_prior_kl: 0.1734 - gp_6_prior_kl: 0.2051 - gp_7_prior_kl: 0.2000 - gp_8_prior_kl: 0.1802 - gp_9_prior_kl: 0.1607 - gp_10_prior_kl: 0.3379 - gp_11_prior_kl: 0.2567 - gp_12_prior_kl: 0.3547 - gp_13_prior_kl: 0.2946 - gp_14_prior_kl: 0.3196 - gp_15_prior_kl: 0.3036 - gp_16_prior_kl: 0.2622 - gp_17_prior_kl: 0.2989 - gp_18_prior_kl: 0.3311 - gp_19_prior_kl: 0.2263\n",
            "Epoch 24/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 84.3666 - gp_0_prior_kl: 0.1997 - gp_1_prior_kl: 0.1818 - gp_2_prior_kl: 0.1852 - gp_3_prior_kl: 0.2745 - gp_4_prior_kl: 0.2172 - gp_5_prior_kl: 0.1622 - gp_6_prior_kl: 0.1987 - gp_7_prior_kl: 0.1937 - gp_8_prior_kl: 0.1708 - gp_9_prior_kl: 0.1518 - gp_10_prior_kl: 0.3382 - gp_11_prior_kl: 0.2562 - gp_12_prior_kl: 0.3553 - gp_13_prior_kl: 0.2940 - gp_14_prior_kl: 0.3209 - gp_15_prior_kl: 0.3036 - gp_16_prior_kl: 0.2589 - gp_17_prior_kl: 0.2968 - gp_18_prior_kl: 0.3267 - gp_19_prior_kl: 0.2303\n",
            "Epoch 25/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 72.8299 - gp_0_prior_kl: 0.1968 - gp_1_prior_kl: 0.1777 - gp_2_prior_kl: 0.1787 - gp_3_prior_kl: 0.2741 - gp_4_prior_kl: 0.2141 - gp_5_prior_kl: 0.1523 - gp_6_prior_kl: 0.1907 - gp_7_prior_kl: 0.1831 - gp_8_prior_kl: 0.1611 - gp_9_prior_kl: 0.1423 - gp_10_prior_kl: 0.3389 - gp_11_prior_kl: 0.2528 - gp_12_prior_kl: 0.3565 - gp_13_prior_kl: 0.2930 - gp_14_prior_kl: 0.3196 - gp_15_prior_kl: 0.3037 - gp_16_prior_kl: 0.2554 - gp_17_prior_kl: 0.2916 - gp_18_prior_kl: 0.3234 - gp_19_prior_kl: 0.2347\n",
            "Epoch 26/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 66.7871 - gp_0_prior_kl: 0.1888 - gp_1_prior_kl: 0.1709 - gp_2_prior_kl: 0.1703 - gp_3_prior_kl: 0.2726 - gp_4_prior_kl: 0.2082 - gp_5_prior_kl: 0.1414 - gp_6_prior_kl: 0.1811 - gp_7_prior_kl: 0.1729 - gp_8_prior_kl: 0.1488 - gp_9_prior_kl: 0.1306 - gp_10_prior_kl: 0.3400 - gp_11_prior_kl: 0.2516 - gp_12_prior_kl: 0.3583 - gp_13_prior_kl: 0.2916 - gp_14_prior_kl: 0.3182 - gp_15_prior_kl: 0.3016 - gp_16_prior_kl: 0.2486 - gp_17_prior_kl: 0.2845 - gp_18_prior_kl: 0.3172 - gp_19_prior_kl: 0.2377\n",
            "Epoch 27/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 60.0420 - gp_0_prior_kl: 0.1808 - gp_1_prior_kl: 0.1613 - gp_2_prior_kl: 0.1614 - gp_3_prior_kl: 0.2726 - gp_4_prior_kl: 0.2018 - gp_5_prior_kl: 0.1318 - gp_6_prior_kl: 0.1729 - gp_7_prior_kl: 0.1622 - gp_8_prior_kl: 0.1378 - gp_9_prior_kl: 0.1180 - gp_10_prior_kl: 0.3408 - gp_11_prior_kl: 0.2522 - gp_12_prior_kl: 0.3603 - gp_13_prior_kl: 0.2894 - gp_14_prior_kl: 0.3182 - gp_15_prior_kl: 0.2994 - gp_16_prior_kl: 0.2432 - gp_17_prior_kl: 0.2771 - gp_18_prior_kl: 0.3160 - gp_19_prior_kl: 0.2420\n",
            "Epoch 28/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 57.1499 - gp_0_prior_kl: 0.1755 - gp_1_prior_kl: 0.1556 - gp_2_prior_kl: 0.1571 - gp_3_prior_kl: 0.2717 - gp_4_prior_kl: 0.1963 - gp_5_prior_kl: 0.1230 - gp_6_prior_kl: 0.1685 - gp_7_prior_kl: 0.1521 - gp_8_prior_kl: 0.1264 - gp_9_prior_kl: 0.1095 - gp_10_prior_kl: 0.3424 - gp_11_prior_kl: 0.2516 - gp_12_prior_kl: 0.3658 - gp_13_prior_kl: 0.2870 - gp_14_prior_kl: 0.3190 - gp_15_prior_kl: 0.2985 - gp_16_prior_kl: 0.2366 - gp_17_prior_kl: 0.2726 - gp_18_prior_kl: 0.3104 - gp_19_prior_kl: 0.2465\n",
            "Epoch 29/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 48.9224 - gp_0_prior_kl: 0.1683 - gp_1_prior_kl: 0.1445 - gp_2_prior_kl: 0.1460 - gp_3_prior_kl: 0.2678 - gp_4_prior_kl: 0.1900 - gp_5_prior_kl: 0.1101 - gp_6_prior_kl: 0.1584 - gp_7_prior_kl: 0.1420 - gp_8_prior_kl: 0.1115 - gp_9_prior_kl: 0.0983 - gp_10_prior_kl: 0.3416 - gp_11_prior_kl: 0.2490 - gp_12_prior_kl: 0.3640 - gp_13_prior_kl: 0.2862 - gp_14_prior_kl: 0.3169 - gp_15_prior_kl: 0.2954 - gp_16_prior_kl: 0.2336 - gp_17_prior_kl: 0.2644 - gp_18_prior_kl: 0.3014 - gp_19_prior_kl: 0.2480\n",
            "Epoch 30/30\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 46.2243 - gp_0_prior_kl: 0.1583 - gp_1_prior_kl: 0.1362 - gp_2_prior_kl: 0.1367 - gp_3_prior_kl: 0.2632 - gp_4_prior_kl: 0.1847 - gp_5_prior_kl: 0.0986 - gp_6_prior_kl: 0.1501 - gp_7_prior_kl: 0.1336 - gp_8_prior_kl: 0.0988 - gp_9_prior_kl: 0.0864 - gp_10_prior_kl: 0.3423 - gp_11_prior_kl: 0.2431 - gp_12_prior_kl: 0.3596 - gp_13_prior_kl: 0.2846 - gp_14_prior_kl: 0.3150 - gp_15_prior_kl: 0.2905 - gp_16_prior_kl: 0.2281 - gp_17_prior_kl: 0.2558 - gp_18_prior_kl: 0.2912 - gp_19_prior_kl: 0.2504\n"
          ]
        }
      ],
      "source": [
        "import gpflux\n",
        "\n",
        "from gpflux.architectures import build_constant_input_dim_deep_gp\n",
        "from gpflux.models import DeepGP\n",
        "\n",
        "for fold in [0]:\n",
        "    train_input,train_output,test_input,test_output = return_data(fold=fold,month='mar',with_scaling=True)\n",
        "    train_output = train_output.reshape(-1,1)\n",
        "    print(train_input.shape,train_output.shape)\n",
        "   \n",
        "    print(\"Fold: \",fold)\n",
        "    print(\"Data received\")\n",
        "\n",
        "    config = gpflux.architectures.Config(\n",
        "        num_inducing=Config.num_inducing, inner_layer_qsqrt_factor=Config.inner_layer_qsqrt_factor, likelihood_noise_variance=Config.likelihood_noise_variance, whiten=True\n",
        "    )\n",
        "    deep_gp: DeepGP = build_constant_input_dim_deep_gp(train_input, num_layers=Config.num_layers, config=config)\n",
        "\n",
        "    training_model: tf.keras.Model = deep_gp.as_training_model()\n",
        "\n",
        "    # Following the Keras procedure we need to compile and pass a optimizer,\n",
        "    # before fitting the model to data\n",
        "    training_model.compile(optimizer=tf.optimizers.Adam(learning_rate=Config.learning_rate))\n",
        "\n",
        "    callbacks = [\n",
        "        # Create callback that reduces the learning rate every time the ELBO plateaus\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\"loss\", factor=0.95, patience=3, min_lr=1e-6, verbose=0),\n",
        "        # Create a callback that writes logs (e.g., hyperparameters, KLs, etc.) to TensorBoard\n",
        "        gpflux.callbacks.TensorBoard(),\n",
        "        # Create a callback that saves the model's weights\n",
        "        tf.keras.callbacks.ModelCheckpoint(filepath=\"ckpts/\", save_weights_only=True, verbose=0),\n",
        "    ]\n",
        "\n",
        "    history = training_model.fit(\n",
        "        {\"inputs\": train_input, \"targets\": train_output},\n",
        "        batch_size=Config.batch_size,\n",
        "        epochs=Config.epochs,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "BFIAHEJLi1Qb"
      },
      "outputs": [],
      "source": [
        "# # From the `DeepGP` model we instantiate a training model which is a `tf.keras.Model`\n",
        "# training_model: tf.keras.Model = deep_gp.as_training_model()\n",
        "\n",
        "# # Following the Keras procedure we need to compile and pass a optimizer,\n",
        "# # before fitting the model to data\n",
        "# training_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01))\n",
        "\n",
        "# callbacks = [\n",
        "#     # Create callback that reduces the learning rate every time the ELBO plateaus\n",
        "#     tf.keras.callbacks.ReduceLROnPlateau(\"loss\", factor=0.95, patience=3, min_lr=1e-6, verbose=0),\n",
        "#     # Create a callback that writes logs (e.g., hyperparameters, KLs, etc.) to TensorBoard\n",
        "#     gpflux.callbacks.TensorBoard(),\n",
        "#     # Create a callback that saves the model's weights\n",
        "#     tf.keras.callbacks.ModelCheckpoint(filepath=\"ckpts/\", save_weights_only=True, verbose=0),\n",
        "# ]\n",
        "\n",
        "# history = training_model.fit(\n",
        "#     {\"inputs\": train_input, \"targets\": train_output},\n",
        "#     batch_size=12,\n",
        "#     epochs=50,\n",
        "#     callbacks=callbacks,\n",
        "#     verbose=0,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "zZGe4sNbi-nL",
        "outputId": "bc016b5d-edd8-4b50-a44d-48481161d614"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Learning rate')"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 3))\n",
        "ax1.plot(history.history[\"loss\"])\n",
        "ax1.set_xlabel(\"Iteration\")\n",
        "ax1.set_ylabel(\"Objective = neg. ELBO\")\n",
        "\n",
        "ax2.plot(history.history[\"lr\"])\n",
        "ax2.set_xlabel(\"Iteration\")\n",
        "ax2.set_ylabel(\"Learning rate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNLgvMO5jBzV",
        "outputId": "bc83b2f3-e23b-48c5-da53-a2bfef11176e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7fb725d7e7f0>\n"
          ]
        }
      ],
      "source": [
        "# def plot(model, X, Y, ax=None):\n",
        "#     if ax is None:\n",
        "#         fig, ax = plt.subplots()\n",
        "\n",
        "#     x_margin = 1.0\n",
        "#     N_test = 100\n",
        "#     X_test = np.linspace(X.min() - x_margin, X.max() + x_margin, N_test).reshape(-1, 1)\n",
        "#     out = model(X_test)\n",
        "\n",
        "#     mu = out.f_mean.numpy().squeeze()\n",
        "#     var = out.f_var.numpy().squeeze()\n",
        "#     X_test = X_test.squeeze()\n",
        "#     lower = mu - 2 * np.sqrt(var)\n",
        "#     upper = mu + 2 * np.sqrt(var)\n",
        "\n",
        "#     ax.set_ylim(Y.min() - 0.5, Y.max() + 0.5)\n",
        "#     ax.plot(X.iloc[:,0], Y, \"kx\", alpha=0.5)\n",
        "#     ax.plot(X_test, mu, \"C1\")\n",
        "\n",
        "#     ax.fill_between(X_test, lower, upper, color=\"C1\", alpha=0.3)\n",
        "\n",
        "\n",
        "prediction_model = deep_gp.as_prediction_model()\n",
        "print(prediction_model)\n",
        "# plot(prediction_model,test_input,test_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "PwxTC83llEf3"
      },
      "outputs": [],
      "source": [
        "# prediction_model = deep_gp.as_prediction_model()\n",
        "from sklearn.metrics import mean_squared_error\n",
        "Test_pred = prediction_model.predict(np.array(test_input))\n",
        "err = mean_squared_error(Test_pred, test_output, squared=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZFJvX9mOpuA",
        "outputId": "a557b084-5441-4d2b-85f6-39ea6d5a9b88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37.90253438840399\n"
          ]
        }
      ],
      "source": [
        "print(err)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cz3RteGXVAQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DeepGP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
