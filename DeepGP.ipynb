{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXp5mAgXfRv9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.backend.set_floatx(\"float64\")  # we want to carry out GP calculations in 64 bit\n",
        "tf.get_logger().setLevel(\"INFO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU-upNQvIk3u"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')\n",
        "\n",
        "# import os\n",
        "# import sys\n",
        "# os.chdir('/content/drive/MyDrive/ML_Project')\n",
        "\n",
        "# ROOT_DIR = '/content/drive/MyDrive/Data/ML_Project'\n",
        "# sys.path.append(ROOT_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OZWWCI5MYVq"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ4eQopyCy6F"
      },
      "outputs": [],
      "source": [
        "def return_data(fold,month,with_scaling, station_id = None):\n",
        "  train_input = pd.read_csv('data/beijing-18/time_feature/'+'/fold'+str(fold)+'/train_data_'+month+'.csv.gz')\n",
        "  test_input = pd.read_csv('data/beijing-18/time_feature'+'/fold'+str(fold)+'/test_data_'+month+'.csv.gz')\n",
        "  if station_id != None:\n",
        "    test_input = test_input[test_input['station_id'] == station_id]\n",
        "  #     test_input = test_input[test_input['station_id' == ]]\n",
        "  test_output = np.array(test_input['PM25_Concentration'])\n",
        "  train_output = np.array(train_input['PM25_Concentration'])\n",
        "  train_input= train_input.drop(['station_id','PM25_Concentration','time','filled'],axis=1)\n",
        "  try:\n",
        "    test_input= test_input.drop(['PM25_Concentration','station_id','time','filled'],axis=1)\n",
        "  except:\n",
        "    test_input= test_input.drop(['station_id','time','filled'],axis=1)\n",
        "  #     test_output= test_output.drop(['time'],axis=1)\n",
        "  if with_scaling:\n",
        "    scaler = MinMaxScaler().fit(train_input)\n",
        "    train_input = pd.DataFrame(scaler.transform(train_input),columns=list(train_input.columns))\n",
        "    test_input = pd.DataFrame(scaler.transform(test_input),columns=list(test_input.columns))\n",
        "  return train_input,train_output,test_input,test_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrvL4A4vMHme"
      },
      "outputs": [],
      "source": [
        "# for fold in [0]:\n",
        "#     train_input,train_output,test_input,test_output = return_data(fold=fold,month='mar',with_scaling=True)\n",
        "#     train_output = train_output.reshape(-1,1)\n",
        "#     print(train_input.shape,train_output.shape)\n",
        "   \n",
        "#     print(\"Fold: \",fold)\n",
        "#     print(\"Data received\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJrTrqNYfxH4"
      },
      "outputs": [],
      "source": [
        "# np.random.seed(42)\n",
        "# X=np.random.rand(100,2)\n",
        "# # noise=np.random.normal(0,1,100)\n",
        "# Y=-8*X[:,0] - 6*X[:,1] + 3\n",
        "# X=X\n",
        "# # print(X)\n",
        "# # X=X.reshape(-1,1)\n",
        "# Y=Y.reshape(-1,1)\n",
        "# print(X.shape)\n",
        "# print\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEGzfSUBg1Pm"
      },
      "outputs": [],
      "source": [
        "# plt.plot(train_input.iloc[:,1], train_output, \"kx\")\n",
        "# plt.xlabel(\"X\")\n",
        "# plt.ylabel(\"Y\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02-TBrbliyWF",
        "outputId": "0eacd47f-2436-482a-856e-6dbb35fa53b6"
      },
      "outputs": [],
      "source": [
        "# !pip install gpflux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLViLwxWg2X3",
        "outputId": "a608a5e6-5aad-4146-ae40-8c5c74cac732"
      },
      "outputs": [],
      "source": [
        "import gpflux\n",
        "\n",
        "from gpflux.architectures import Config, build_constant_input_dim_deep_gp\n",
        "from gpflux.models import DeepGP\n",
        "\n",
        "for fold in [0]:\n",
        "    train_input,train_output,test_input,test_output = return_data(fold=fold,month='mar',with_scaling=True)\n",
        "    train_output = train_output.reshape(-1,1)\n",
        "    print(train_input.shape,train_output.shape)\n",
        "   \n",
        "    print(\"Fold: \",fold)\n",
        "    print(\"Data received\")\n",
        "\n",
        "    config = Config(\n",
        "        num_inducing=25, inner_layer_qsqrt_factor=1e-5, likelihood_noise_variance=1e-2, whiten=True\n",
        "    )\n",
        "    deep_gp: DeepGP = build_constant_input_dim_deep_gp(train_input, num_layers=10, config=config)\n",
        "\n",
        "    training_model: tf.keras.Model = deep_gp.as_training_model()\n",
        "\n",
        "    # Following the Keras procedure we need to compile and pass a optimizer,\n",
        "    # before fitting the model to data\n",
        "    training_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01))\n",
        "\n",
        "    callbacks = [\n",
        "        # Create callback that reduces the learning rate every time the ELBO plateaus\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\"loss\", factor=0.95, patience=3, min_lr=1e-6, verbose=0),\n",
        "        # Create a callback that writes logs (e.g., hyperparameters, KLs, etc.) to TensorBoard\n",
        "        gpflux.callbacks.TensorBoard(),\n",
        "        # Create a callback that saves the model's weights\n",
        "        tf.keras.callbacks.ModelCheckpoint(filepath=\"ckpts/\", save_weights_only=True, verbose=0),\n",
        "    ]\n",
        "\n",
        "    history = training_model.fit(\n",
        "        {\"inputs\": train_input, \"targets\": train_output},\n",
        "        batch_size=12,\n",
        "        epochs=20,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFIAHEJLi1Qb"
      },
      "outputs": [],
      "source": [
        "# # From the `DeepGP` model we instantiate a training model which is a `tf.keras.Model`\n",
        "# training_model: tf.keras.Model = deep_gp.as_training_model()\n",
        "\n",
        "# # Following the Keras procedure we need to compile and pass a optimizer,\n",
        "# # before fitting the model to data\n",
        "# training_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01))\n",
        "\n",
        "# callbacks = [\n",
        "#     # Create callback that reduces the learning rate every time the ELBO plateaus\n",
        "#     tf.keras.callbacks.ReduceLROnPlateau(\"loss\", factor=0.95, patience=3, min_lr=1e-6, verbose=0),\n",
        "#     # Create a callback that writes logs (e.g., hyperparameters, KLs, etc.) to TensorBoard\n",
        "#     gpflux.callbacks.TensorBoard(),\n",
        "#     # Create a callback that saves the model's weights\n",
        "#     tf.keras.callbacks.ModelCheckpoint(filepath=\"ckpts/\", save_weights_only=True, verbose=0),\n",
        "# ]\n",
        "\n",
        "# history = training_model.fit(\n",
        "#     {\"inputs\": train_input, \"targets\": train_output},\n",
        "#     batch_size=12,\n",
        "#     epochs=50,\n",
        "#     callbacks=callbacks,\n",
        "#     verbose=0,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "zZGe4sNbi-nL",
        "outputId": "bc016b5d-edd8-4b50-a44d-48481161d614"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 3))\n",
        "ax1.plot(history.history[\"loss\"])\n",
        "ax1.set_xlabel(\"Iteration\")\n",
        "ax1.set_ylabel(\"Objective = neg. ELBO\")\n",
        "\n",
        "ax2.plot(history.history[\"lr\"])\n",
        "ax2.set_xlabel(\"Iteration\")\n",
        "ax2.set_ylabel(\"Learning rate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNLgvMO5jBzV",
        "outputId": "bc83b2f3-e23b-48c5-da53-a2bfef11176e"
      },
      "outputs": [],
      "source": [
        "# def plot(model, X, Y, ax=None):\n",
        "#     if ax is None:\n",
        "#         fig, ax = plt.subplots()\n",
        "\n",
        "#     x_margin = 1.0\n",
        "#     N_test = 100\n",
        "#     X_test = np.linspace(X.min() - x_margin, X.max() + x_margin, N_test).reshape(-1, 1)\n",
        "#     out = model(X_test)\n",
        "\n",
        "#     mu = out.f_mean.numpy().squeeze()\n",
        "#     var = out.f_var.numpy().squeeze()\n",
        "#     X_test = X_test.squeeze()\n",
        "#     lower = mu - 2 * np.sqrt(var)\n",
        "#     upper = mu + 2 * np.sqrt(var)\n",
        "\n",
        "#     ax.set_ylim(Y.min() - 0.5, Y.max() + 0.5)\n",
        "#     ax.plot(X.iloc[:,0], Y, \"kx\", alpha=0.5)\n",
        "#     ax.plot(X_test, mu, \"C1\")\n",
        "\n",
        "#     ax.fill_between(X_test, lower, upper, color=\"C1\", alpha=0.3)\n",
        "\n",
        "\n",
        "prediction_model = deep_gp.as_prediction_model()\n",
        "print(prediction_model)\n",
        "# plot(prediction_model,test_input,test_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwxTC83llEf3"
      },
      "outputs": [],
      "source": [
        "# prediction_model = deep_gp.as_prediction_model()\n",
        "from sklearn.metrics import mean_squared_error\n",
        "Test_pred = prediction_model.predict(np.array(test_input))\n",
        "err = mean_squared_error(Test_pred, test_output, squared=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZFJvX9mOpuA",
        "outputId": "a557b084-5441-4d2b-85f6-39ea6d5a9b88"
      },
      "outputs": [],
      "source": [
        "print(err)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGksItolSWv3"
      },
      "outputs": [],
      "source": [
        "#41.72707824766764\n",
        "#41.62436334687556"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cz3RteGXVAQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DeepGP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
