{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import gpytorch\n",
    "from gpytorch.means import ConstantMean, LinearMean\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.variational import VariationalStrategy, CholeskyVariationalDistribution\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.models import ApproximateGP, GP\n",
    "from gpytorch.mlls import VariationalELBO, AddedLossTerm\n",
    "from gpytorch.likelihoods import GaussianLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models.deep_gps import DeepGPLayer, DeepGP\n",
    "from gpytorch.mlls import DeepApproximateMLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(Config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(loadmat(\"./elevators.mat\")[\"data\"], device = device).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Points = 16599  \n",
    "Number of features = 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing features data between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, :-1]\n",
    "X = X - X.min(axis=0).values\n",
    "X = 2 * (X / X.max(axis=0).values) - 1\n",
    "\n",
    "y = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(0.8 * len(X))\n",
    "X_train = X[:n_train].contiguous()\n",
    "X_test = X[n_train:].contiguous()\n",
    "\n",
    "y_train = y[:n_train].contiguous()\n",
    "y_test = y[n_train:].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDeepGPHiddenLayer(DeepGPLayer):\n",
    "    def __init__(self, input_dims, output_dims, num_inducing=128, mean_type='constant'):\n",
    "        if output_dims is None:\n",
    "            inducing_points = torch.randn(num_inducing, input_dims)\n",
    "            batch_shape = torch.Size([])\n",
    "        else:\n",
    "            inducing_points = torch.randn(output_dims, num_inducing, input_dims)\n",
    "            batch_shape = torch.Size([output_dims])\n",
    "\n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            num_inducing_points=num_inducing,\n",
    "            batch_shape=batch_shape\n",
    "        )\n",
    "\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self,\n",
    "            inducing_points,\n",
    "            variational_distribution,\n",
    "            learn_inducing_locations=True\n",
    "        )\n",
    "\n",
    "        super(ToyDeepGPHiddenLayer, self).__init__(variational_strategy, input_dims, output_dims)\n",
    "\n",
    "        if mean_type == 'constant':\n",
    "            self.mean_module = ConstantMean(batch_shape=batch_shape)\n",
    "        else:\n",
    "            self.mean_module = LinearMean(input_dims)\n",
    "        self.covar_module = ScaleKernel(\n",
    "            RBFKernel(batch_shape=batch_shape, ard_num_dims=input_dims),\n",
    "            batch_shape=batch_shape, ard_num_dims=None\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "    def __call__(self, x, *other_inputs, **kwargs):\n",
    "        \"\"\"\n",
    "        Overriding __call__ isn't strictly necessary, but it lets us add concatenation based skip connections\n",
    "        easily. For example, hidden_layer2(hidden_layer1_outputs, inputs) will pass the concatenation of the first\n",
    "        hidden layer's outputs and the input data to hidden_layer2.\n",
    "        \"\"\"\n",
    "        if len(other_inputs):\n",
    "            if isinstance(x, gpytorch.distributions.MultitaskMultivariateNormal):\n",
    "                x = x.rsample()\n",
    "\n",
    "            processed_inputs = [\n",
    "                inp.unsqueeze(0).expand(gpytorch.settings.num_likelihood_samples.value(), *inp.shape)\n",
    "                for inp in other_inputs\n",
    "            ]\n",
    "\n",
    "            x = torch.cat([x] + processed_inputs, dim=-1)\n",
    "\n",
    "        return super().__call__(x, are_samples=bool(len(other_inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepGP(DeepGP):\n",
    "    def __init__(self, train_x_shape):\n",
    "        hidden_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=train_x_shape[-1],\n",
    "            output_dims=8,\n",
    "            mean_type='linear'\n",
    "        )\n",
    "\n",
    "        second_hidden_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=8,\n",
    "            output_dims=4,\n",
    "            mean_type='linear'\n",
    "        )\n",
    "\n",
    "        third_hidden_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=4,\n",
    "            output_dims=2,\n",
    "            mean_type='linear'\n",
    "        )\n",
    "\n",
    "        last_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=third_hidden_layer.output_dims,\n",
    "            output_dims=None,\n",
    "            mean_type='constant'\n",
    "        )\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.second_hidden_layer = second_hidden_layer\n",
    "        self.third_hidden_layer = third_hidden_layer\n",
    "        self.last_layer = last_layer\n",
    "        self.likelihood = GaussianLikelihood()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        z = self.hidden_layer(inputs)\n",
    "        z = self.second_hidden_layer(z)\n",
    "        z = self.third_hidden_layer(z)\n",
    "        output = self.last_layer(z)\n",
    "        return output\n",
    "\n",
    "    def predict(self, test_loader):\n",
    "        with torch.no_grad():\n",
    "            mus = []\n",
    "            variances = []\n",
    "            lls = []\n",
    "            for x_batch, y_batch in test_loader:\n",
    "                preds = self.likelihood(self(x_batch))\n",
    "                mus.append(preds.mean)\n",
    "                variances.append(preds.variance)\n",
    "                lls.append(model.likelihood.log_marginal(y_batch, model(x_batch)))\n",
    "\n",
    "        return torch.cat(mus, dim=-1), torch.cat(variances, dim=-1), torch.cat(lls, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepGP(train_x_shape = X_train.shape).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc6276553c746449bbee9d248810b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96970136de640588c35e134573f13a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "RMSE: 0.25172096490859985, NLL: 0.6334934830665588\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ed0ae4329f4673a11302b98dedc127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c662a2071754414e96cc770c38871a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5d1918960a43ad97de32bd45f44a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4c8b03338540e5809c64b261796975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33aefd0d9ae40ba9afcb3d02fce6e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "RMSE: 0.18546243011951447, NLL: 0.35586220026016235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4d1d194ea04af794bdd472cde2ea40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "], lr=0.01)\n",
    "mll = DeepApproximateMLL(VariationalELBO(model.likelihood, model, X_train.shape[-2]))\n",
    "\n",
    "epochs_iter = tqdm.notebook.tqdm(range(num_epochs), desc=\"Epoch\")\n",
    "for i in epochs_iter:\n",
    "    # Within each iteration, we will go over each minibatch of data\n",
    "    minibatch_iter = tqdm.notebook.tqdm(train_loader, desc=\"Minibatch\", leave=False)\n",
    "    for x_batch, y_batch in minibatch_iter:\n",
    "        with gpytorch.settings.num_likelihood_samples(num_samples):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = -mll(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            minibatch_iter.set_postfix(loss=loss.item())\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        print(i)\n",
    "        test_dataset = TensorDataset(X_test, y_test)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1024)\n",
    "\n",
    "        model.eval()\n",
    "        predictive_means, predictive_variances, test_lls = model.predict(test_loader)\n",
    "\n",
    "        rmse = torch.mean(torch.pow(predictive_means.mean(0) - y_test, 2)).sqrt()\n",
    "        print(f\"RMSE: {rmse.item()}, NLL: {-test_lls.mean().item()}\")\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024)\n",
    "\n",
    "model.eval()\n",
    "predictive_means, predictive_variances, test_lls = model.predict(test_loader)\n",
    "\n",
    "rmse = torch.mean(torch.pow(predictive_means.mean(0) - y_test, 2)).sqrt()\n",
    "print(f\"RMSE: {rmse.item()}, NLL: {-test_lls.mean().item()}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c70e5ee2d2c28a093660d06d1dd4b62023c712f6a8515efc39e65872fc2efeaf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('sachin_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
